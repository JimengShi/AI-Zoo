{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start to Run Aurora - A Weather Foundation Model from Microsoft \n",
    "\n",
    "\n",
    "\n",
    "**Author: Jimeng Shi (UIUC)**\n",
    "\n",
    "**References:**\n",
    "\n",
    "Microsoft provides detailed materials:\n",
    "[Paper](https://arxiv.org/pdf/2405.13063v2), \n",
    "[Code](https://github.com/microsoft/aurora), \n",
    "and \n",
    "[Document](https://microsoft.github.io/aurora/intro.html).\n",
    "\n",
    "\n",
    "\n",
    "### ðŸš€ Getting Started\n",
    "\n",
    "Welcome! This notebook will guide you step by step â€” feel free to run each cell as you go.  \n",
    "\n",
    "Youâ€™ll learn the brief introduction of Aurora, and how to run Aurora in a zero-shot model using dummy data.\n",
    "\n",
    "If you encounter any issues or have questions along the way, donâ€™t hesitate to ask a helper. Weâ€™re here to support you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: Aurora - a global weather foundation model\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://raw.githubusercontent.com/JimengShi/AI-Zoo/main/figures/aurora_arch.png\" alt=\"aurora_arch\" width=\"1200\"/> \n",
    "    <p style=\"font-size: 16px; margin-top: 5px;\">Figure 1: Aurora AI Architecture</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "- **Pretraining:** heterogeneous datasets with different resolutions, variables, and pressure levels. The pre-training process takes <span style=\"color:red;\">2.5 weeks on 32 A100 GPUs</span>.\n",
    "  \n",
    "- **Fine-tuning:** multiple operational forecasting scenarios at different resolutions (e.g., atmospheric chemistry and air quality at 0.4Â°, wave modelling at 0.25Â°, hurricane tracking at 0.25Â° and weather forecasting at 0.1Â°)\n",
    "\n",
    "- **Performance:** \n",
    "    - 5-day global air pollution forecasts at 0.4Â° resolution, outperforming resource-intensive numerical atmospheric chemistry simulations on 74% of targets;\n",
    "    - 10-day global ocean wave forecasts at 0.25Â° resolution, exceeding costly numerical models on 86% of targets;\n",
    "    - 5-day tropical cyclone track forecasts, outperforming seven operational forecasting centres on 100% of targets;\n",
    "    - 10-day global weather forecasts at 0.1Â° resolution, surpassing state-of-the-art numerical models on 92% of targets while also improving performance on extreme events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Python Environment Configurations\n",
    "\n",
    "**Option 1:** set up the environment in the terminal. Please ensure python>=3.10\n",
    "\n",
    "- conda create --name <env_name> python==3.10\n",
    "- conda activate <env_name>\n",
    "- pip install microsoft-aurora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2:** set up the environment in jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.18\n"
     ]
    }
   ],
   "source": [
    "# Check python version since aurora requires python>=3.10\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: microsoft-aurora in /home/jovyan/.local/geoai/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: azure-storage-blob in /home/jovyan/.local/geoai/lib/python3.11/site-packages (from microsoft-aurora) (12.27.1)\n",
      "Requirement already satisfied: einops in /home/jovyan/.local/geoai/lib/python3.11/site-packages (from microsoft-aurora) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (0.20.3)\n",
      "Requirement already satisfied: netcdf4 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (1.6.4)\n",
      "Requirement already satisfied: numpy in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (1.26.4)\n",
      "Requirement already satisfied: pydantic in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (2.7.1)\n",
      "Requirement already satisfied: scipy in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (1.13.0)\n",
      "Requirement already satisfied: timm in /home/jovyan/.local/geoai/lib/python3.11/site-packages (from microsoft-aurora) (1.0.22)\n",
      "Requirement already satisfied: torch in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (2.3.0)\n",
      "Requirement already satisfied: xarray in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from microsoft-aurora) (2023.6.0)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /home/jovyan/.local/geoai/lib/python3.11/site-packages (from azure-storage-blob->microsoft-aurora) (1.36.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from azure-storage-blob->microsoft-aurora) (42.0.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from azure-storage-blob->microsoft-aurora) (4.9.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/jovyan/.local/geoai/lib/python3.11/site-packages (from azure-storage-blob->microsoft-aurora) (0.7.2)\n",
      "Requirement already satisfied: filelock in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from huggingface-hub->microsoft-aurora) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from huggingface-hub->microsoft-aurora) (2023.10.0)\n",
      "Requirement already satisfied: requests in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from huggingface-hub->microsoft-aurora) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from huggingface-hub->microsoft-aurora) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from huggingface-hub->microsoft-aurora) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from huggingface-hub->microsoft-aurora) (23.2)\n",
      "Requirement already satisfied: cftime in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from netcdf4->microsoft-aurora) (1.6.2)\n",
      "Requirement already satisfied: certifi in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from netcdf4->microsoft-aurora) (2024.7.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from pydantic->microsoft-aurora) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from pydantic->microsoft-aurora) (2.18.2)\n",
      "Requirement already satisfied: torchvision in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from timm->microsoft-aurora) (0.18.0)\n",
      "Requirement already satisfied: safetensors in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from timm->microsoft-aurora) (0.4.2)\n",
      "Requirement already satisfied: sympy in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from torch->microsoft-aurora) (1.12)\n",
      "Requirement already satisfied: networkx in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from torch->microsoft-aurora) (3.1)\n",
      "Requirement already satisfied: jinja2 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from torch->microsoft-aurora) (3.1.3)\n",
      "Requirement already satisfied: pandas>=1.4 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from xarray->microsoft-aurora) (2.1.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob->microsoft-aurora) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from pandas>=1.4->xarray->microsoft-aurora) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from pandas>=1.4->xarray->microsoft-aurora) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from pandas>=1.4->xarray->microsoft-aurora) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from requests->huggingface-hub->microsoft-aurora) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from requests->huggingface-hub->microsoft-aurora) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from requests->huggingface-hub->microsoft-aurora) (1.26.18)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from jinja2->torch->microsoft-aurora) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from sympy->torch->microsoft-aurora) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from torchvision->timm->microsoft-aurora) (10.0.0)\n",
      "Requirement already satisfied: pycparser in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->microsoft-aurora) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/iguide.purdue.edu/software/conda/geoai/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4->xarray->microsoft-aurora) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install microsoft-aurora if your python version works\n",
    "!pip install microsoft-aurora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Prepare a Batch of Input Data\n",
    "\n",
    "This notebook is using the dummy data as input. Feel free to play with different input sizes and shapes using your data. All variables in a batch are **unnormalized**. Normalisation happens internally in the model. \n",
    "\n",
    "\n",
    "\n",
    "It requires the `dictionary` to save the data, which means you need to transform/save your data into a dictionary. Batches contain four things: \n",
    " \n",
    "- `Batch.surf_vars` is a dictionary mapping names of surface-level variables to the numerical values of the variables. \n",
    "    - The surface-level variables are in the form `(b, t, h, w)` where `b` is the batch size, `t` the history dimension, `h` the number of latitudes, and `w` the number of longitudes.\n",
    "    - Aurora models produce the prediction for the next step based on the current step `surf_vars[:, 1, :, :]` and previous step `surf_vars[:, 0, :, :]` must correspond to the previous step.\n",
    "\n",
    "- `Batch.static_vars` is a dictionary mapping names of static variables to the numerical values of the variables. \n",
    "\n",
    "- `Batch.atmos_vars` is a dictionary mapping names of atmospheric variables to the numerical values of the variables. It is in the form `(b, t, c, h, w)` where `b` is the batch size, `t` the history dimension, `c` the number of pressure levels, `h` the number of latitudes, and `w` the number of longitudes. All atmospheric variables must contain the same collection of pressure levels in the same order.\n",
    "\n",
    "- `Batch.metadata` includes latitude, longtitude, time point, and the pressure levels of the atmospheric variables. Pressure levels: 50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000\n",
    "\n",
    "<span style=\"color:red;\">**Notes:**</span> Latitude, longtitude, and atmos_levels should be matched. Refer the form of a Batch to the [official tutorial](https://microsoft.github.io/aurora/batch.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "from aurora import Batch, Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = Batch(\n",
    "#     surf_vars={k: torch.randn(1, 2, 17, 32) for k in (\"2t\", \"10u\", \"10v\", \"msl\")},\n",
    "#     static_vars={k: torch.randn(17, 32) for k in (\"lsm\", \"z\", \"slt\")},\n",
    "#     atmos_vars={k: torch.randn(1, 2, 4, 17, 32) for k in (\"z\", \"u\", \"v\", \"t\", \"q\")},\n",
    "#     metadata=Metadata(\n",
    "#         lat=torch.linspace(90, -90, 17),\n",
    "#         lon=torch.linspace(0, 360, 32 + 1)[:-1],\n",
    "#         time=(datetime(2020, 6, 1, 12, 0),),\n",
    "#         atmos_levels=(100, 250, 500, 850),\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch(\n",
    "    surf_vars={k: torch.randn(1, 2, 32, 64) for k in (\"2t\", \"10u\", \"10v\", \"msl\")},\n",
    "    static_vars={k: torch.randn(32, 64) for k in (\"lsm\", \"z\", \"slt\")},\n",
    "    atmos_vars={k: torch.randn(1, 2, 3, 32, 64) for k in (\"z\", \"u\", \"v\", \"t\", \"q\")},\n",
    "    metadata=Metadata(\n",
    "        lat=torch.linspace(90, -90, 32),\n",
    "        lon=torch.linspace(0, 360, 64 + 1)[:-1],\n",
    "        time=(datetime(2020, 6, 1, 12, 0),),\n",
    "        atmos_levels=(100, 500, 850),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch(\n",
    "    surf_vars={k: torch.randn(1, 2, 32, 64) for k in (\"2t\", \"10u\", \"10v\", \"msl\")},\n",
    "    static_vars={k: torch.randn(32, 64) for k in (\"lsm\", \"z\", \"slt\")},\n",
    "    atmos_vars={k: torch.randn(1, 2, 5, 32, 64) for k in (\"z\", \"u\", \"v\", \"t\", \"q\")},\n",
    "    metadata=Metadata(\n",
    "        lat=torch.linspace(90, -90, 32),\n",
    "        lon=torch.linspace(0, 360, 64 + 1)[:-1],\n",
    "        time=(datetime(2020, 6, 1, 12, 0),),\n",
    "        atmos_levels=(50, 100, 500, 850, 1000),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤– Import Pre-trained Aurora Model\n",
    "\n",
    "Aurora has [several versions](https://microsoft.github.io/aurora/models.html) of verious sizes. You can have multiple options to import the pre-trained Aurora model. Please run **only ONE** of them as the model used in this notebook. \n",
    "\n",
    "Reference link: [https://microsoft.github.io/aurora/models.html](https://microsoft.github.io/aurora/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import Aurora\n",
    "from aurora import AuroraSmallPretrained\n",
    "\n",
    "### Pick only ONE and comment others\n",
    "# model = Aurora()\n",
    "model = AuroraSmallPretrained()\n",
    "model.load_checkpoint()\n",
    "# model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-small-pretrained.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncommnet the following line to run the model on GPU if available, otherwise, keep it in comment. \n",
    "You will need approximately 40 GB of GPU memory for running the regular model on global 0.25 degree data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0\n",
      "CUDA available: False\n",
      "No GPU detected. Running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(\"cuda\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ One-Step Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuroraSmallPretrained(\n",
       "  (encoder): Perceiver3DEncoder(\n",
       "    (surf_mlp): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (surf_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (pos_embed): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (scale_embed): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lead_time_embed): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (absolute_time_embed): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (atmos_levels_embed): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (surf_token_embeds): LevelPatchEmbed(\n",
       "      (weights): ParameterDict(\n",
       "          (10u): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (10v): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (2t): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (lsm): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (msl): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (slt): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (z): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "      )\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (atmos_token_embeds): LevelPatchEmbed(\n",
       "      (weights): ParameterDict(\n",
       "          (q): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (t): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (u): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (v): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "          (z): Parameter containing: [torch.FloatTensor of size 256x1x2x4x4]\n",
       "      )\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (level_agg): PerceiverResampler(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): PerceiverAttention(\n",
       "            (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (to_kv): Linear(in_features=256, out_features=512, bias=False)\n",
       "            (to_out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          )\n",
       "          (1): MLP(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (3): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2-3): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (backbone): Swin3DTransformerBackbone(\n",
       "    (time_mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): Basic3DEncoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=256, window_size=(2, 6, 12), num_heads=4\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging3D(\n",
       "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Basic3DEncoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-5): 6 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(2, 6, 12), num_heads=8\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging3D(\n",
       "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Basic3DEncoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=1024, window_size=(2, 6, 12), num_heads=16\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): Basic3DDecoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=1024, window_size=(2, 6, 12), num_heads=16\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsample): PatchSplitting3D(\n",
       "          (lin1): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (lin2): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Basic3DDecoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-5): 6 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(2, 6, 12), num_heads=8\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (upsample): PatchSplitting3D(\n",
       "          (lin1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (lin2): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Basic3DDecoderLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x Swin3DTransformerBlock(\n",
       "            (norm1): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): WindowAttention(\n",
       "              dim=256, window_size=(2, 6, 12), num_heads=4\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): AdaptiveLayerNorm(\n",
       "              (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "              (ln_modulation): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Perceiver3DDecoder(\n",
       "    (level_decoder): PerceiverResampler(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): PerceiverAttention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (1): MLP(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "              (3): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2-3): 2 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (surf_heads): ParameterDict(\n",
       "        (10u): Object of type: LinearPatchReconstruction\n",
       "        (10v): Object of type: LinearPatchReconstruction\n",
       "        (2t): Object of type: LinearPatchReconstruction\n",
       "        (msl): Object of type: LinearPatchReconstruction\n",
       "      (10u): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (10v): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (2t): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (msl): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "    )\n",
       "    (atmos_heads): ParameterDict(\n",
       "        (q): Object of type: LinearPatchReconstruction\n",
       "        (t): Object of type: LinearPatchReconstruction\n",
       "        (u): Object of type: LinearPatchReconstruction\n",
       "        (v): Object of type: LinearPatchReconstruction\n",
       "        (z): Object of type: LinearPatchReconstruction\n",
       "      (q): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (t): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (u): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (v): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "      (z): LinearPatchReconstruction(in_features=512, out_features=16, bias=True)\n",
       "    )\n",
       "    (atmos_levels_embed): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    pred = model.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2t', '10u', '10v', 'msl'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.surf_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['z', 'u', 'v', 't', 'q'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.atmos_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.surf_vars[\"2t\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 32, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.atmos_vars[\"z\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Autoregressive Roll-Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import rollout\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred for pred in rollout(model, batch, steps=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2t', '10u', '10v', 'msl'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-1].surf_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['z', 'u', 'v', 't', 'q'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-1].atmos_vars.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-1].surf_vars[\"2t\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 32, 64])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-1].atmos_vars[\"z\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
